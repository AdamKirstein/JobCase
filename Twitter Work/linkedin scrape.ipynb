{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to grab all people with CDL from Facebook.\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "time_delay = randint(3,6)\n",
    "\n",
    "#prepare linkedin login creads\n",
    "usr=input('Enter Email Id:')\n",
    "pwd=input('Enter Password:')\n",
    "\n",
    "#setup Chrome drvier\n",
    "option = webdriver.ChromeOptions()\n",
    "#adding incognito \n",
    "option.add_argument('â€” incognito')\n",
    "\n",
    "#establishing the driver \n",
    "browser = webdriver.Chrome(executable_path='/Users/adamkirstein/Downloads/chromedriver', chrome_options=option)\n",
    "#connecting browser to linked\n",
    "browser.get(\"https://www.linkedin.com\")\n",
    "\n",
    "print(\"Opened linkedin\")\n",
    "\n",
    "#resting 1 second to appear human :P\n",
    "sleep(time_delay)\n",
    "\n",
    "#entering login creds \n",
    "username_box = browser.find_element_by_class_name('login-email')\n",
    "username_box.send_keys(usr)\n",
    "print (\"Email Id entered\")\n",
    "sleep(time_delay)\n",
    "\n",
    "password_box = browser.find_element_by_class_name('login-password')\n",
    "password_box.send_keys(pwd)\n",
    "print (\"Password entered\")\n",
    "# sleep for 0.5 seconds\n",
    "sleep(time_delay)\n",
    "\n",
    "#sending login creds\n",
    "login_box = browser.find_element_by_xpath('//*[@type=\"submit\"]')\n",
    "login_box.click()\n",
    "# sleep for 0.5 seconds\n",
    "sleep(time_delay)\n",
    "print('Logged in ')\n",
    "\n",
    "#querying nav bar to get to results page\n",
    "navigation_bar = browser.find_element_by_class_name(\"nav-search-bar\")\n",
    "navigation_bar.click()\n",
    "print('nav bar selected')\n",
    "\n",
    "query_button = browser.find_element_by_class_name('nav-search-controls')\n",
    "query_button.click()\n",
    "print('query made')\n",
    "sleep(time_delay)\n",
    "\n",
    "#selecting 'More' button to toggle drop-down for companies\n",
    "try:\n",
    "    click_more = browser.find_element_by_class_name(\"search-vertical-filter__dropdown-trigger-text\")\n",
    "\n",
    "except:\n",
    "    click_more = browser.find_element_by_xpath(\"//span[@class='search-vertical-filter__dropdown-trigger-text']\")\n",
    "click_more.click()\n",
    "\n",
    "\n",
    "sleep(time_delay)\n",
    "\n",
    "#navigating to first page of scrape. \n",
    "click_company = browser.find_element_by_xpath(\"//li[@class='search-vertical-filter__dropdown-list-item p0']\")\n",
    "click_company.click()\n",
    "print(\"navigated\")\n",
    "sleep(time_delay)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### START OF SCRAPE ###\n",
    "#zoom out of page and press space 2 times to load all companies. \n",
    "browser.execute_script(\"document.body.style.zoom='50%'\")\n",
    "\n",
    "actions = ActionChains(browser)\n",
    "for _ in range(2):\n",
    "    actions.send_keys(Keys.SPACE).perform()\n",
    "sleep(3)\n",
    "#create empty df to hold results\n",
    "comp_df = pd.DataFrame()\n",
    "#counter to control loop (also appending i to end of url to make it go to next page)\n",
    "i = 1#start at one because page 1 =1 so if you start at 0 you will scrape the first page twice. \n",
    "item_names=[]\n",
    "while True:\n",
    "    #select the elements for the target titles\n",
    "    titles = WebDriverWait(browser, 5).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, 'h3[class=\"search-result__title t-16 t-black t-bold\"]')))\n",
    "    #iterate through the html of titles and append\n",
    "    for title in titles:\n",
    "        item_names.append(title.text)\n",
    "        df = comp_df.append(item_names)\n",
    "      #push i forward (making page go from one to 2)  \n",
    "    i+=1\n",
    "    try:\n",
    "        #repeat the zoom and space for each new page because chrome is dumb and wont keep the page zoomed\n",
    "        browser.execute_script(\"document.body.style.zoom='50%'\")\n",
    "        sleep(4)\n",
    "        actions.send_keys(Keys.SPACE).perform()\n",
    "        sleep(4)\n",
    "        browser.get(\"https://www.linkedin.com/search/results/companies/?origin=SWITCH_SEARCH_VERTICAL&page=\"+str(i)+'')\n",
    "        sleep(3)\n",
    "    except:\n",
    "        #stop scraper when ~= 100 (all pages will have been scraped)\n",
    "        if i >= 100:\n",
    "            break\n",
    "\n",
    "    \n",
    "    \n",
    "print (\"Done\")\n",
    "input('Press anything to quit')\n",
    "browser.quit()\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
